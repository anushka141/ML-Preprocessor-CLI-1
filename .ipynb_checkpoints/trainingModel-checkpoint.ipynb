{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries and load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning samples: 60000       |              Testing samples: 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D \n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MNIST dataset from keras library\n",
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the MNIST dataset into training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  68  45 131 131 131 101  68  92\n",
      "   44   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   19 170   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  29 112  89   0\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 120 254 251 127\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 197 254 254  91\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  64 247 254 236  50\n",
      "   40 107   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 184 254 254  91   0\n",
      "    6  14   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 203 254 254  71   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  23 218 254 254  71   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 113 254 255 239  53   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 210 254 254 195   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  62 242 254 241  88   0   0\n",
      "    0  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  86 254 254 189   0   0   0\n",
      "   28 104   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 106 254 254 168   0   0   0\n",
      "   40  91   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 216 254 245  51   0   0   0\n",
      "   35  80   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 216 254 102   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  55 239 254  52   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 166 254 210  23   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 223 252 104   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 223 169   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the values of each pixel of any random index before normalising the training set\n",
    "print(x_train[67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking maximum value of the channel to know if images are in gray level\n",
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing \n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03117587 0.45018348 0.7331795  0.8459256\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16859145 0.32614753 0.62238481 0.66704959 0.53330092\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16208871 0.45084006 0.60673033 0.61008472 0.13225983 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.01882619 0.17503039 0.11603991 0.\n",
      "  0.         0.         0.         0.         0.         0.01423579\n",
      "  0.32899195 0.47925435 0.55397117 0.1943415  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09913097 0.38698271 0.512589   0.20113584 0.\n",
      "  0.         0.         0.         0.         0.         0.11000382\n",
      "  0.13801613 0.43568577 0.44605471 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.04369476 0.42773179 0.34096315 0.11460323 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08153224\n",
      "  0.25035485 0.43758006 0.13669418 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.02552568 0.25084575\n",
      "  0.23864063 0.38183783 0.04811136 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27695079\n",
      "  0.40602421 0.26709432 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.39990225 0.47010352\n",
      "  0.42518366 0.12299584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08699889 0.28859825\n",
      "  0.40602421 0.24436289 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.39990225 0.47010352\n",
      "  0.42518366 0.12299584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07520243 0.24330256\n",
      "  0.40602421 0.16101431 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.58709054 0.47010352\n",
      "  0.42518366 0.26985654 0.01045899 0.         0.         0.\n",
      "  0.         0.         0.         0.07998068 0.05603318 0.30930485\n",
      "  0.32899195 0.01894286 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.57858198 0.47010352\n",
      "  0.42518366 0.46444697 0.4099925  0.20628582 0.03094397 0.\n",
      "  0.         0.17421888 0.1806877  0.31822101 0.31702984 0.3248348\n",
      "  0.28084678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00850856 0.23040647\n",
      "  0.4235031  0.46444697 0.52922501 0.52717486 0.64466614 0.70082479\n",
      "  0.70082479 0.71972391 0.77175087 0.43053431 0.37306302 0.32742313\n",
      "  0.25356452 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.19662644 0.3561372  0.52922501 0.52717486 0.65240213 0.71208302\n",
      "  0.71208302 0.67117111 0.60943819 0.43053431 0.37306302 0.22000763\n",
      "  0.07542742 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00917879 0.05438676 0.30838688 0.32233307 0.04221836\n",
      "  0.04221836 0.03427257 0.01837502 0.0918927  0.37306302 0.23812591\n",
      "  0.06258871 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0204206  0.26099666 0.32742313\n",
      "  0.11554839 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23653861 0.34947011 0.32742313\n",
      "  0.11554839 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33013303 0.37306302 0.30024571\n",
      "  0.03851613 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34544848 0.27426768 0.17212362\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42372745 0.24625109 0.11906295\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22122316 0.01769469 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the values of each pixel after normalizing the sets\n",
    "print(x_test[67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the data sets\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make images 4D, we need to reshape them\n",
    "# Reshaping image in order to suit it for convolution operation\n",
    "input_shape = [28, 28, 1]\n",
    "x_train = x_train.reshape(len(x_train), input_shape[0], input_shape[1], input_shape[2])\n",
    "x_test = x_test.reshape(len(x_test), input_shape[0], input_shape[1], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the data sets after reshaping\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,554\n",
      "Trainable params: 100,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a neural network\n",
    "model = Sequential()\n",
    "\n",
    "# First CNN layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=[28, 28, 1]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "# Second CNN layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Third CNN layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Fully connected layers \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5)) #Regularizing\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# Summarizing the performance of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2648/4200 [=================>............] - ETA: 16s - loss: 0.3911 - accuracy: 0.8749"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=15, validation_data=(x_test, y_test), validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model is saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Saving our trained model\n",
    "model.save('HAMARA_PYARA_MODEL.keras')\n",
    "print(\"[INFO] Model is saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model using MNIST test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOSS]:  0.0306325051933527\n",
      "[ACCURACY]:  0.9930999875068665\n"
     ]
    }
   ],
   "source": [
    "# Ensuring if \"HAMARA_PAYARA_MODEL\" is worth training\n",
    "performance = model.evaluate(x_test, y_test, verbose=0)\n",
    "loss = performance[0]\n",
    "accuracy = performance[1]\n",
    "print(\"[LOSS]: \",loss)\n",
    "print(\"[ACCURACY]: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to predict \"HAMARA_PAYARA_MODEL\"\n",
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O/P] HAMARA_PAYARA_MODEL says: It's a 5\n"
     ]
    }
   ],
   "source": [
    "# TRIAL NO. - 1\n",
    "# Predicting \"HAMARA_PAYARA_MODEL\" taking random index inputs\n",
    "predictionMax = np.argmax(prediction[127])\n",
    "\n",
    "# Printing model's O/P\n",
    "print(\"[O/P] HAMARA_PAYARA_MODEL says: It's a\",predictionMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking whether the O/P is correct or not by plotting the image at index 127\n",
    "plt.imshow(x_test[127])\n",
    "print(\"It's a 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O/P] HAMARA_PAYARA_MODEL says: It's a 7\n"
     ]
    }
   ],
   "source": [
    "# TRIAL NO. - 2\n",
    "# Predicting \"HAMARA_PAYARA_MODEL\" taking random index inputs\n",
    "predictionMax2 = np.argmax(prediction[0])\n",
    "\n",
    "# Printing model's O/P\n",
    "print(\"[O/P] HAMARA_PAYARA_MODEL says: It's a\",predictionMax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's 7(MY FAV DIGIT)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAANeklEQVR4nO3dbYxc5XnG8evyZr0GG4jNy7IxVsBAWxHSmnTrlAYVIpSIoFYmX1D8gboSykZVkJIKVUX0Q/iIqiYoUtNIm+DEVJQoEiCsCBVcKxKKWiEW5BiDAzauDXb8AgJqjGOvd/fuhz1GG9jzzDLv9v3/SauZPfecc26PfO05M8+ceRwRAnD2W9TrBgB0B2EHkiDsQBKEHUiCsANJfKKbO1vsoViipd3cJZDKCb2vyTjp+Wothd32LZK+L2lA0o8j4v7S45doqT7vm1vZJYCCZ2Nrba3p03jbA5J+IOkrkq6RtN72Nc1uD0BntfKafa2k3RGxJyImJf1M0rr2tAWg3VoJ+0pJb8z5fX+17PfYHrM9YXvilE62sDsArej4u/ERMR4RoxExOqihTu8OQI1Wwn5A0qo5v19WLQPQh1oJ+3OSrrZ9he3Fkr4maXN72gLQbk0PvUXElO27JD2l2aG3jRHxUts6A9BWLY2zR8STkp5sUy8AOoiPywJJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSaGnKZtt7Jb0naVrSVESMtqMpAO3XUtgrX4yIt9qwHQAdxGk8kESrYQ9JT9t+3vbYfA+wPWZ7wvbEKZ1scXcAmtXqafwNEXHA9iWSttj+TUQ8M/cBETEuaVySzveKaHF/AJrU0pE9Ig5Ut0ckPS5pbTuaAtB+TYfd9lLb552+L+nLkna0qzEA7dXKafywpMdtn97Of0TEf7alKwBt13TYI2KPpD9pYy8AOoihNyAJwg4kQdiBJAg7kARhB5Jox4UwKRz6+7+orZ28/r3iupPHFxfrcXygWL/qkVPF+uLdB2trUwcPFddFHhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkX6Nf/8G+1tfH/+1Rx3TVL9hXr706fW6xvvf4zxfpjT11fW1v2+uriuoumyl8eNHmBi3U1KGumtO8Gqzb439lo/alz6mvnHir/u1f85H/KGz8DcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ1+gz9/zd7W1ExeWB5vPe326WH/3qvL17L8bKQxWSxqcLKx7aXk8eeidcu/HV5b3HY2G4Qv/9IHJ8souX8avmfLXBGjgimO1ta9/dmtx3Ud/ckl542cgjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7Av0yYc6d33z0hbXX7S0fgu+bKS4buzbX974H1zeREdzFIbpPdlgIP3Qm8XynruvbaKhWf/6yo3F+oh2Nr3tftXwyG57o+0jtnfMWbbC9hbbu6rb5Z1tE0CrFnIa/1NJt3xo2T2StkbE1ZK2Vr8D6GMNwx4Rz0h6+0OL10naVN3fJOm29rYFoN2afc0+HBGnJxg7JGm47oG2xySNSdISlb9rDUDntPxufESEpNqrLSJiPCJGI2J0UEOt7g5Ak5oN+2HbI5JU3R5pX0sAOqHZsG+WtKG6v0HSE+1pB0CnNHzNbvsRSTdJusj2fknfkXS/pJ/bvlPSPkm3d7JJlM28/3598ZXdrW18+29aW78Vaz9bLE8Pla/Vn/lt/ecPVv+gfDJa/gaCM1PDsEfE+prSzW3uBUAH8XFZIAnCDiRB2IEkCDuQBGEHkuASV/TMwPnnF+uvrVtW3kCDr7G+fHP9JbTTu/aUVz4LcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0fPHPviHxXrU+eUL2EdPFYeaB96453a2tl4CWsjHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2dFRA394VW3t0PUDDdYuj7Ovfrg8pXPGa9ZLOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Ojjl57YW0tGnzv+3l7y8ei6V3/20xLaTU8stveaPuI7R1zlt1n+4DtbdXPrZ1tE0CrFnIa/1NJt8yz/IGIWFP9PNnetgC0W8OwR8Qzkt7uQi8AOqiVN+jusr29Os1fXvcg22O2J2xPnNLJFnYHoBXNhv2Hkq6UtEbSQUnfrXtgRIxHxGhEjA5qqMndAWhVU2GPiMMRMR0RM5J+JGlte9sC0G5Nhd32yJxfvyppR91jAfSHhuPsth+RdJOki2zvl/QdSTfZXqPZC473SvpG51pEP/Pg4mL93avqr1n3TPl69U89daRYn57J+O3vzWsY9ohYP8/iBzvQC4AO4uOyQBKEHUiCsANJEHYgCcIOJMElrmjJ+391XbH+u+GZ2toFr5avcZ1+ZXdTPWF+HNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2VHkP/1Msf7bG8tj5QMn6uuXbj1cXJcLWNuLIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e3KLli4t1vf+9QXFerj+enVJOr9wSfr0rj3FddFeHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2c92Ll9vfviOPy7WJz9ZHkcfeqd8vBj+xWu1tanimmi3hkd226ts/9L2y7Zfsv2tavkK21ts76pul3e+XQDNWshp/JSkuyPiGkl/Lumbtq+RdI+krRFxtaSt1e8A+lTDsEfEwYh4obr/nqSdklZKWidpU/WwTZJu61CPANrgY71mt325pOskPStpOCIOVqVDkoZr1hmTNCZJS3Ru040CaM2C3423vUzSo5K+HRFH59YiIiTFfOtFxHhEjEbE6KCGWmoWQPMWFHbbg5oN+sMR8Vi1+LDtkao+IulIZ1oE0A4NT+NtW9KDknZGxPfmlDZL2iDp/ur2iY50iJZ8YviSYv3ExeWhuZoTtg98+hdHi/WpQ+Wvi0b3LOQ1+xck3SHpRdvbqmX3ajbkP7d9p6R9km7vSIcA2qJh2CPiV5Lq/vzf3N52AHQKH5cFkiDsQBKEHUiCsANJEHYgCS5xPQsMXHxxbe31v7mypW2vero8cXJM7Ghp++gejuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GeBozeurq2dWla+Hn3RqfL17Oe++laxXh6FRz/hyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOfgaYufG6Yv3wn9X/zR442e5ucKbiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSSxkfvZVkh6SNKzZybrHI+L7tu+T9HVJb1YPvTcinuxUo5kd+dw5xfrM4pna2sDJ8vXqg+Xp1eUTk+UH4IyxkA/VTEm6OyJesH2epOdtb6lqD0TEv3SuPQDtspD52Q9KOljdf8/2TkkrO90YgPb6WK/ZbV8u6TpJz1aL7rK93fZG28tr1hmzPWF74pT47CbQKwsOu+1lkh6V9O2IOCrph5KulLRGs0f+7863XkSMR8RoRIwOaqj1jgE0ZUFhtz2o2aA/HBGPSVJEHI6I6YiYkfQjSWs71yaAVjUMu21LelDSzoj43pzlI3Me9lVJTOcJ9LGFvBv/BUl3SHrR9rZq2b2S1tteo9nhuL2SvtGB/tCiJW+Vh95GfrytWJ86fryN3aCXFvJu/K8kzfc/hjF14AzCJ+iAJAg7kARhB5Ig7EAShB1IgrADSfBV0meASx/4745tu/7iWJxtOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiO7tzH5T0r45iy6S9FbXGvh4+rW3fu1LordmtbO3T0fExfMVuhr2j+zcnoiI0Z41UNCvvfVrXxK9NatbvXEaDyRB2IEkeh328R7vv6Rfe+vXviR6a1ZXeuvpa3YA3dPrIzuALiHsQBI9CbvtW2y/Ynu37Xt60UMd23ttv2h7m+2JHvey0fYR2zvmLFthe4vtXdXtvHPs9ai3+2wfqJ67bbZv7VFvq2z/0vbLtl+y/a1qeU+fu0JfXXneuv6a3faApFclfUnSfknPSVofES93tZEatvdKGo2Inn8Aw/ZfSjom6aGIuLZa9s+S3o6I+6s/lMsj4h/7pLf7JB3r9TTe1WxFI3OnGZd0m6S/VQ+fu0Jft6sLz1svjuxrJe2OiD0RMSnpZ5LW9aCPvhcRz0h6+0OL10naVN3fpNn/LF1X01tfiIiDEfFCdf89SaenGe/pc1foqyt6EfaVkt6Y8/t+9dd87yHpadvP2x7rdTPzGI6Ig9X9Q5KGe9nMPBpO491NH5pmvG+eu2amP28Vb9B91A0R8TlJX5H0zep0tS/F7Guwfho7XdA03t0yzzTjH+jlc9fs9Oet6kXYD0haNef3y6plfSEiDlS3RyQ9rv6bivrw6Rl0q9sjPe7nA/00jfd804yrD567Xk5/3ouwPyfpattX2F4s6WuSNvegj4+wvbR640S2l0r6svpvKurNkjZU9zdIeqKHvfyefpnGu26acfX4uev59OcR0fUfSbdq9h351yT9Uy96qOlrtaRfVz8v9bo3SY9o9rTulGbf27hT0oWStkraJem/JK3oo97+XdKLkrZrNlgjPertBs2eom+XtK36ubXXz12hr648b3xcFkiCN+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/B8MV+XZddtaWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking whether the O/P is correct or not by plotting the image at index 0\n",
    "plt.imshow(x_test[0])\n",
    "print(\"It's 7(MY FAV DIGIT)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74b0a38879f80463ab999397bfa9db9d3cd5fd53c7393138d0c98665aeeeaeaa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
