{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries and load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning samples: 60000       |              Testing samples: 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D \n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MNIST dataset from keras library\n",
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the MNIST dataset into training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  68  45 131 131 131 101  68  92\n",
      "   44   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   19 170   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  29 112  89   0\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 120 254 251 127\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 197 254 254  91\n",
      "   40 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  64 247 254 236  50\n",
      "   40 107   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 184 254 254  91   0\n",
      "    6  14   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 203 254 254  71   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  23 218 254 254  71   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 113 254 255 239  53   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 210 254 254 195   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  62 242 254 241  88   0   0\n",
      "    0  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  86 254 254 189   0   0   0\n",
      "   28 104   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 106 254 254 168   0   0   0\n",
      "   40  91   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 216 254 245  51   0   0   0\n",
      "   35  80   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 216 254 102   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  55 239 254  52   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 166 254 210  23   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 223 252 104   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 223 169   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the values of each pixel of any random index before normalising the training set\n",
    "print(x_train[67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking maximum value of the channel to know if images are in gray level\n",
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing \n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03117587 0.45018348 0.7331795  0.8459256\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16859145 0.32614753 0.62238481 0.66704959 0.53330092\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16208871 0.45084006 0.60673033 0.61008472 0.13225983 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.01882619 0.17503039 0.11603991 0.\n",
      "  0.         0.         0.         0.         0.         0.01423579\n",
      "  0.32899195 0.47925435 0.55397117 0.1943415  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09913097 0.38698271 0.512589   0.20113584 0.\n",
      "  0.         0.         0.         0.         0.         0.11000382\n",
      "  0.13801613 0.43568577 0.44605471 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.04369476 0.42773179 0.34096315 0.11460323 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08153224\n",
      "  0.25035485 0.43758006 0.13669418 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.02552568 0.25084575\n",
      "  0.23864063 0.38183783 0.04811136 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27695079\n",
      "  0.40602421 0.26709432 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.39990225 0.47010352\n",
      "  0.42518366 0.12299584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08699889 0.28859825\n",
      "  0.40602421 0.24436289 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.39990225 0.47010352\n",
      "  0.42518366 0.12299584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07520243 0.24330256\n",
      "  0.40602421 0.16101431 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.58709054 0.47010352\n",
      "  0.42518366 0.26985654 0.01045899 0.         0.         0.\n",
      "  0.         0.         0.         0.07998068 0.05603318 0.30930485\n",
      "  0.32899195 0.01894286 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.57858198 0.47010352\n",
      "  0.42518366 0.46444697 0.4099925  0.20628582 0.03094397 0.\n",
      "  0.         0.17421888 0.1806877  0.31822101 0.31702984 0.3248348\n",
      "  0.28084678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00850856 0.23040647\n",
      "  0.4235031  0.46444697 0.52922501 0.52717486 0.64466614 0.70082479\n",
      "  0.70082479 0.71972391 0.77175087 0.43053431 0.37306302 0.32742313\n",
      "  0.25356452 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.19662644 0.3561372  0.52922501 0.52717486 0.65240213 0.71208302\n",
      "  0.71208302 0.67117111 0.60943819 0.43053431 0.37306302 0.22000763\n",
      "  0.07542742 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00917879 0.05438676 0.30838688 0.32233307 0.04221836\n",
      "  0.04221836 0.03427257 0.01837502 0.0918927  0.37306302 0.23812591\n",
      "  0.06258871 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0204206  0.26099666 0.32742313\n",
      "  0.11554839 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23653861 0.34947011 0.32742313\n",
      "  0.11554839 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33013303 0.37306302 0.30024571\n",
      "  0.03851613 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34544848 0.27426768 0.17212362\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42372745 0.24625109 0.11906295\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22122316 0.01769469 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the values of each pixel after normalizing the sets\n",
    "print(x_test[67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the data sets\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make images 4D, we need to reshape them\n",
    "# Reshaping image in order to suit it for convolution operation\n",
    "input_shape = [28, 28, 1]\n",
    "x_train = x_train.reshape(len(x_train), input_shape[0], input_shape[1], input_shape[2])\n",
    "x_test = x_test.reshape(len(x_test), input_shape[0], input_shape[1], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the data sets after reshaping\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,554\n",
      "Trainable params: 100,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a neural network\n",
    "model = Sequential()\n",
    "\n",
    "# First CNN layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=[28, 28, 1]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "# Second CNN layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Third CNN layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Fully connected layers \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5)) #Regularizing\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# Summarizing the performance of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4200/4200 [==============================] - 57s 13ms/step - loss: 0.3051 - accuracy: 0.9035 - val_loss: 0.0739 - val_accuracy: 0.9780\n",
      "Epoch 2/15\n",
      "4200/4200 [==============================] - 55s 13ms/step - loss: 0.1178 - accuracy: 0.9644 - val_loss: 0.0522 - val_accuracy: 0.9847\n",
      "Epoch 3/15\n",
      "4200/4200 [==============================] - 56s 13ms/step - loss: 0.0891 - accuracy: 0.9739 - val_loss: 0.0478 - val_accuracy: 0.9855\n",
      "Epoch 4/15\n",
      "4200/4200 [==============================] - 54s 13ms/step - loss: 0.0734 - accuracy: 0.9779 - val_loss: 0.0545 - val_accuracy: 0.9847\n",
      "Epoch 5/15\n",
      "4200/4200 [==============================] - 54s 13ms/step - loss: 0.0650 - accuracy: 0.9801 - val_loss: 0.0368 - val_accuracy: 0.9897\n",
      "Epoch 6/15\n",
      "4200/4200 [==============================] - 59s 14ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.0397 - val_accuracy: 0.9893\n",
      "Epoch 7/15\n",
      "4200/4200 [==============================] - 59s 14ms/step - loss: 0.0557 - accuracy: 0.9833 - val_loss: 0.0383 - val_accuracy: 0.9886\n",
      "Epoch 8/15\n",
      "4200/4200 [==============================] - 61s 14ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.0434 - val_accuracy: 0.9877\n",
      "Epoch 9/15\n",
      "4200/4200 [==============================] - 58s 14ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0403 - val_accuracy: 0.9888\n",
      "Epoch 10/15\n",
      "4200/4200 [==============================] - 56s 13ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 0.0366 - val_accuracy: 0.9901\n",
      "Epoch 11/15\n",
      "4200/4200 [==============================] - 56s 13ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.0387 - val_accuracy: 0.9902\n",
      "Epoch 12/15\n",
      "4200/4200 [==============================] - 61s 15ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0406 - val_accuracy: 0.9897\n",
      "Epoch 13/15\n",
      "4200/4200 [==============================] - 58s 14ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.0479 - val_accuracy: 0.9889\n",
      "Epoch 14/15\n",
      "4200/4200 [==============================] - 61s 15ms/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.0463 - val_accuracy: 0.9893\n",
      "Epoch 15/15\n",
      "4200/4200 [==============================] - 64s 15ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0368 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=15, validation_data=(x_test, y_test), validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Saving our trained model\n",
    "model.save('Handwritten.keras')\n",
    "print(\"Model is saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model using MNIST test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOSS]:  0.03052486851811409\n",
      "[ACCURACY]:  0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "performance = model.evaluate(x_test, y_test, verbose=0)\n",
    "loss = performance[0]\n",
    "accuracy = performance[1]\n",
    "print(\"[LOSS]: \",loss)\n",
    "print(\"[ACCURACY]: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Predicting taking random index inputs\n",
    "predictionMax = np.argmax(prediction[127])\n",
    "\n",
    "print(predictionMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking whether the O/P is correct or not by plotting the image at index 127\n",
    "plt.imshow(x_test[127])\n",
    "print(\"It's a \",predictionMax)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74b0a38879f80463ab999397bfa9db9d3cd5fd53c7393138d0c98665aeeeaeaa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
